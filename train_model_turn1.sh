python3 train.py --model_type albert --model_name_or_path pretrained_models/albert_large/ --output_dir saved_models --max_seq_length 128 --do_train --per_gpu_train_batch_size 32 --per_gpu_eval_batch_size 32 --gradient_accumulation_steps 1 --learning_rate 5e-5 --weight_decay 0.1 --adam_epsilon 1e-8 --max_grad_norm 5.0 --num_train_epochs 3.0 --warmup_steps 0 --seed 42 --data_root data/mwz2.2/ --train_data train_dials.json --dev_data dev_dials.json --test_data test_dials.json --ontology_data schema.json --vocab_path assets/vocab.txt --save_dir saved_models --random_seed 42 --batch_size 8 --enc_warmup 0.01 --dec_warmup 0.01 --enc_lr 5e-6 --base_lr 1e-4 --turn 1 --dropout 0.0 --hidden_dropout_prob 0.0 --attention_probs_dropout_prob 0.1 --word_dropout 0.1 --n_history 0 --max_seq_length 256 --sketch_weight 0.55 --answer_weight 0.6 --generation_weight 0.2 --extraction_weight 0.1
